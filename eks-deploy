To deploy an Amazon EKS (Elastic Kubernetes Service) cluster using **Terraform**, you'll need to follow a few essential steps: 

1. **Create an IAM Role** for EKS and worker nodes.
2. **Set up a VPC** with appropriate subnets, routing tables, and security groups.
3. **Create the EKS Cluster**.
4. **Create the EKS Worker Nodes** (EC2 instances running in an Auto Scaling Group).

### Sample Terraform Configuration to Deploy an EKS Cluster:

Here’s a basic sample Terraform configuration to deploy an EKS cluster. It assumes that you have already configured your AWS credentials and region in your environment.

#### 1. **Provider Configuration** (`provider.tf`):

```hcl
provider "aws" {
  region = "us-west-2"  # Change this to your preferred AWS region
}
```

#### 2. **VPC and Subnet Configuration** (`vpc.tf`):

We will set up a simple VPC with public subnets for the worker nodes and a private subnet for the EKS cluster control plane.

```hcl
resource "aws_vpc" "eks_vpc" {
  cidr_block = "10.0.0.0/16"
  enable_dns_support = true
  enable_dns_hostnames = true
}

resource "aws_subnet" "eks_public_subnet" {
  vpc_id = aws_vpc.eks_vpc.id
  cidr_block = "10.0.1.0/24"
  availability_zone = "us-west-2a"
  map_public_ip_on_launch = true
}

resource "aws_subnet" "eks_private_subnet" {
  vpc_id = aws_vpc.eks_vpc.id
  cidr_block = "10.0.2.0/24"
  availability_zone = "us-west-2a"
}

resource "aws_internet_gateway" "eks_gateway" {
  vpc_id = aws_vpc.eks_vpc.id
}

resource "aws_route_table" "eks_route_table" {
  vpc_id = aws_vpc.eks_vpc.id
}

resource "aws_route" "internet_route" {
  route_table_id         = aws_route_table.eks_route_table.id
  destination_cidr_block = "0.0.0.0/0"
  gateway_id             = aws_internet_gateway.eks_gateway.id
}
```

#### 3. **EKS Cluster Configuration** (`eks-cluster.tf`):

Here we define the **EKS Cluster** itself.

```hcl
resource "aws_eks_cluster" "my_eks_cluster" {
  name     = "my-eks-cluster"
  role_arn = aws_iam_role.eks_cluster_role.arn
  vpc_config {
    subnet_ids = [aws_subnet.eks_public_subnet.id, aws_subnet.eks_private_subnet.id]
  }

  depends_on = [aws_iam_role_policy_attachment.eks_cluster_policy]
}
```

#### 4. **IAM Roles and Policies** (`iam.tf`):

We need IAM roles for both the EKS cluster and the worker nodes.

```hcl
resource "aws_iam_role" "eks_cluster_role" {
  name = "eks-cluster-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action    = "sts:AssumeRole"
        Principal = {
          Service = "eks.amazonaws.com"
        }
        Effect    = "Allow"
        Sid       = ""
      },
    ]
  })
}

resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {
  role       = aws_iam_role.eks_cluster_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
}

resource "aws_iam_role" "eks_worker_role" {
  name = "eks-worker-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action    = "sts:AssumeRole"
        Principal = {
          Service = "ec2.amazonaws.com"
        }
        Effect    = "Allow"
        Sid       = ""
      },
    ]
  })
}

resource "aws_iam_role_policy_attachment" "eks_worker_policy" {
  role       = aws_iam_role.eks_worker_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
}

resource "aws_iam_role_policy_attachment" "eks_vpc_policy" {
  role       = aws_iam_role.eks_worker_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonVPCFullAccess"
}
```

#### 5. **Launch Config for Worker Nodes** (`worker-nodes.tf`):

This will define the worker nodes that will run in the **EKS Cluster**.

```hcl
resource "aws_launch_configuration" "eks_worker_launch_config" {
  name          = "eks-worker-launch-config"
  image_id      = "ami-0abcdef1234567890"  # Replace with the latest Amazon EKS-optimized AMI ID
  instance_type = "t3.medium"
  security_groups = [aws_security_group.eks_worker_sg.id]
  iam_instance_profile = aws_iam_instance_profile.eks_worker_profile.id
  associate_public_ip_address = true
}

resource "aws_security_group" "eks_worker_sg" {
  name        = "eks-worker-sg"
  description = "Allow all inbound traffic for EKS worker nodes"

  ingress {
    from_port   = 0
    to_port     = 65535
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 65535
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

resource "aws_iam_instance_profile" "eks_worker_profile" {
  name = "eks-worker-profile"
  role = aws_iam_role.eks_worker_role.name
}
```

#### 6. **Auto Scaling Group for Worker Nodes** (`asg.tf`):

Define an **Auto Scaling Group** to manage the worker nodes dynamically.

```hcl
resource "aws_autoscaling_group" "eks_worker_asg" {
  desired_capacity     = 2
  max_size             = 3
  min_size             = 1
  launch_configuration = aws_launch_configuration.eks_worker_launch_config.id
  vpc_zone_identifier  = [aws_subnet.eks_public_subnet.id]

  tag {
    key                 = "Name"
    value               = "eks-worker-node"
    propagate_at_launch = true
  }
}
```

#### 7. **Outputs** (`outputs.tf`):

Finally, let's define the outputs to retrieve important details like the EKS cluster endpoint and kubeconfig.

```hcl
output "eks_cluster_name" {
  value = aws_eks_cluster.my_eks_cluster.name
}

output "eks_cluster_endpoint" {
  value = aws_eks_cluster.my_eks_cluster.endpoint
}

output "eks_cluster_certificate_authority_data" {
  value = aws_eks_cluster.my_eks_cluster.certificate_authority[0].data
}
```

---

### Final Notes:

- **AWS CLI**: You should have AWS CLI configured with the correct credentials (`aws configure`) for Terraform to interact with AWS.
- **Amazon EKS-Optimized AMI**: You’ll need the proper **Amazon EKS-optimized AMI** for your region. You can find the AMI ID for your region [here](https://docs.aws.amazon.com/eks/latest/userguide/eks-optimized-ami.html).
- **Scaling**: The Auto Scaling Group for worker nodes (`desired_capacity`, `min_size`, `max_size`) can be modified to meet your cluster's needs.
- **Terraform Initialization and Apply**:
  1. Initialize your Terraform configuration:  
     ```bash
     terraform init
     ```
  2. Plan and apply the configuration:  
     ```bash
     terraform plan
     terraform apply
     ```
  After this, you can use the `aws eks update-kubeconfig` command to configure `kubectl` with the new EKS cluster and begin managing your Kubernetes resources.

---

This is a simplified version of a Terraform configuration to deploy an EKS cluster. Depending on your specific use case, you might need to extend the configuration with additional security settings, IAM policies, monitoring, etc.

